import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.neighbors import KNeighborsClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc, precision_recall_curve

# 1. è¯»å–æ•°æ®
df = pd.read_csv("/home/xingxin/Downloads/Isolation_point/random_xyz_data.csv")  # ğŸ‘ˆ æ›¿æ¢ä¸ºä½ çš„ CSV æ–‡ä»¶

# 2. æå–ç‰¹å¾å’Œæ ‡ç­¾
X = df[['X', 'Y', 'Z']]  # ä¸‰è½´æ•°æ®
y = df['label']         # 0ï¼ˆæ­£å¸¸ï¼‰æˆ– 1ï¼ˆå¼‚å¸¸ï¼‰

# 3. æ ‡å‡†åŒ–ï¼ˆé‡è¦ï¼ï¼‰
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

# 4. åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)

# ======================
# æ¨¡å‹1ï¼šKNN
# ======================
knn = KNeighborsClassifier(n_neighbors=5)
knn.fit(X_train, y_train)
knn_pred = knn.predict(X_test)

# æ‰“å°åˆ†ç±»æŠ¥å‘Š
print("\nğŸ“Š KNN åˆ†ç±»ç»“æœï¼š")
print(classification_report(y_test, knn_pred))

# è®¡ç®—æ··æ·†çŸ©é˜µ
knn_cm = confusion_matrix(y_test, knn_pred)

# ======================
# æ¨¡å‹2ï¼šé€»è¾‘å›å½’
# ======================
lr = LogisticRegression()
lr.fit(X_train, y_train)
lr_pred = lr.predict(X_test)

# æ‰“å°åˆ†ç±»æŠ¥å‘Š
print("\nğŸ“Š é€»è¾‘å›å½’åˆ†ç±»ç»“æœï¼š")
print(classification_report(y_test, lr_pred))

# è®¡ç®—æ··æ·†çŸ©é˜µ
lr_cm = confusion_matrix(y_test, lr_pred)

# ======================
# å¯è§†åŒ–ï¼šæ··æ·†çŸ©é˜µ
# ======================

# è®¾ç½®å›¾å½¢æ ·å¼
sns.set(style="whitegrid")

# KNN æ··æ·†çŸ©é˜µ
plt.figure(figsize=(10, 7))
plt.subplot(1, 2, 1)
sns.heatmap(knn_cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Normal", "Abnormal"], yticklabels=["Normal", "Abnormal"])
plt.title("KNN Confusion Matrix")
plt.xlabel("Pre Label")
plt.ylabel("True Label")

# é€»è¾‘å›å½’ æ··æ·†çŸ©é˜µ
plt.subplot(1, 2, 2)
sns.heatmap(lr_cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Normal", "Abnormal"], yticklabels=["Normal", "Abnormal"])
plt.title("Logistic Regression  confusion Matrix")
plt.xlabel("Pre Label")
plt.ylabel("True Label")

plt.tight_layout()
plt.show()

# ======================
# å¯è§†åŒ–ï¼šROC æ›²çº¿
# ======================
# è®¡ç®— ROC æ›²çº¿
fpr_knn, tpr_knn, _ = roc_curve(y_test, knn.predict_proba(X_test)[:, 1])
fpr_lr, tpr_lr, _ = roc_curve(y_test, lr.predict_proba(X_test)[:, 1])

# è®¡ç®— AUC
roc_auc_knn = auc(fpr_knn, tpr_knn)
roc_auc_lr = auc(fpr_lr, tpr_lr)

# ç»˜åˆ¶ ROC æ›²çº¿
plt.figure(figsize=(8, 6))
plt.plot(fpr_knn, tpr_knn, color="blue", label=f"KNN (AUC = {roc_auc_knn:.2f})")
plt.plot(fpr_lr, tpr_lr, color="green", label=f"Logistic Regression (AUC = {roc_auc_lr:.2f})")
plt.plot([0, 1], [0, 1], color="gray", linestyle="--")
plt.xlabel("å‡é˜³æ€§ç‡ (FPR)")
plt.ylabel("çœŸæ­£ç‡ (TPR)")
plt.title("ROC æ›²çº¿")
plt.legend(loc="lower right")
plt.show()

# ======================
# å¯è§†åŒ–ï¼šPrecision-Recall æ›²çº¿
# ======================
# è®¡ç®— Precision-Recall æ›²çº¿
precision_knn, recall_knn, _ = precision_recall_curve(y_test, knn.predict_proba(X_test)[:, 1])
precision_lr, recall_lr, _ = precision_recall_curve(y_test, lr.predict_proba(X_test)[:, 1])

# ç»˜åˆ¶ Precision-Recall æ›²çº¿
plt.figure(figsize=(8, 6))
plt.plot(recall_knn, precision_knn, color="blue", label="KNN")
plt.plot(recall_lr, precision_lr, color="green", label="Logistic Regression")
plt.xlabel(" (Recall)")
plt.ylabel(" (Precision)")
plt.title("Precision-Recall ")
plt.legend(loc="lower left")
plt.show()
